{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA663 Final Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the Bayesian hierarchical clustering algorithm described in the paper by Heller and Ghahramani (2005) and optimized the algorithm's speed using Cython. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering is an unsupervised learning algorithm that organizes data into a binary tree. By cutting the tree at various heights, one can acquire clustering structures of the data. The traditional hierarchical clustering algorithm is the  agglomerative hierarchical clustering method. This algorithm starts with each data point being in it's own cluster and uses a bottom-up approach of iteratively merging the most similar clusters until all the data has been grouped into one cluster. The similarity of clusters is evaluated using a pre-specified distance measure (e.g. Euclidean distance).\n",
    "\n",
    "The major drawback of the traditional hierarchical clustering method is that it does not provide intuitive guidance to choosing the correct number of clusters or the appropriate distance measure. Furthermore, the algorithm does not define a probabilistic model for the data, thus it is not able to give predictions or cluster new data points into existing clusters.\n",
    "\n",
    "Heller and Ghahramani (2005) proposed the Bayesian hierarchical clustering model to overcome those aforementioned problems. The model is similar to the traditional hierarchical clustering method, but Bayesian hierarchical clustering merges data using the marginal likelihood of data. The major advantage of Bayesian hierarchical clustering over the traditional method is that it has a natural way to choose the correct number of clusters, and it can also give predictions of the probability of assigning new data into existing clusters. On the other hand, the disadvantage of the algorithm is that it is more computationally intensive since it requires calculating the marginal likelihood at each step. Bayesian hierarchical clustering works best when the user has no prior knowledge on the number of clusters or when the user wants to predict the probability of new data belonging to any existing clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Bayesian hierarchical clustering algorithm starts with every data point being in its own node. Afterwards, it iteratively merge the nodes with the highest merge probability until there is only a single node left (all data points in the same node). Merge probability is defined as the the ratio of the marginal likelihood of the two nodes being in the same cluster against the marginal likelihood of the nodes being partitioned in all possible ways which does not violate the existing tree structure. The tree can then be cut at the step where the merge probability is less than 50%.\n",
    "\n",
    "In mathematical terms, if we represent the hypothesis that the nodes are in the same cluster by $H_1^k$ and the tree structure using $T$, then we can write our the algorithm:\n",
    "\n",
    "1.Input: data = {$x^{(1)}, ..., x^{(n)}$}, model(likelihood) $p(x \\mid \\theta)$, prior $p(\\theta \\mid \\beta)$\n",
    "\n",
    "2.Initialize: number of clusters $c = n$, $D_i = $ {$x^{(i)}$} for $i = 1, ..., n$\n",
    "\n",
    "3.while $c > 1$ do\n",
    "\n",
    "Find the pair of clusters $D_i$ and $D_j$ that has the highest merge probability: $r_k = \\frac{\\pi_k p(D_k \\mid H_1^k)}{p(D_k \\mid T_k)}$ \n",
    "        \n",
    "Merge $D_i, D_j$ into $D_k$, $T_i$, and $T_j$ into $T_k$\n",
    "\n",
    "Delete $D_i, D_j$ and $c = c - 1$\n",
    "\n",
    "end while\n",
    "\n",
    "To calculate the merge probabilities, we need to compute $p(D_k \\mid T_k)$, which is\n",
    "$$\n",
    "p(D_k \\mid T_k) = \\pi_k p(D_k \\mid H_1^k) + (1 - \\pi_k) p(D_i \\mid T_i)p(D_j \\mid T_j)\n",
    "$$\n",
    "The term $\\pi_k$ can be calculated by\n",
    "\n",
    "1.Initialize: each leaf $i$ with $d_i = \\alpha, \\pi_i = 1$ \n",
    "\n",
    "2.for each internal node $k$ do\n",
    "\n",
    "$d_k = \\alpha \\Gamma(n_k) + d_{left_k}d_{right_k}$\n",
    "\n",
    "$\\pi_k = \\frac{\\alpha \\Gamma(n_k)}{d_k}$\n",
    "\n",
    "end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-21bd9efc65bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cython'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'import numpy as np\\nimport itertools as it\\nfrom scipy.special import gamma\\nfrom scipy.special import multigammaln\\nfrom numpy.math cimport INFINITY\\nfrom scipy.stats import multivariate_normal\\ncimport numpy as np\\n\\n\\ndef BHC_cython(data, likelihood, alpha):\\n    \"\"\"`\\n    Bayesian hierarchical clustering algorithm, direct implementation from paper.\\n    \\n    Parameters\\n    ----------\\n    data : 2D numpy array\\n        Data with rows as observations and columns as variables.\\n    likelihood : function\\n        Function that returns the marginal likelihood of data in BHC model.\\n    alpha : float\\n        Concentration parameter in model.\\n        \\n    Returns\\n    -------\\n    T_record : list(list(int))\\n        Cluster structure in each iteration.\\n    rk_record : list(float)\\n        Merge probability (rk) in each iteration.\\n    \"\"\"\\n    \\n    cdef int n, c, i, j\\n    cdef float max_rk\\n    cdef int merge_index1, merge_index2\\n    cdef double pi_k, rk\\n    cdef int node_index, item_index\\n    cdef double likelihood_i, likelihood_j, likelihood_k\\n    cdef T_record, rk_record\\n    \\n    n = data.shape[0]\\n    p = data.shape[1]\\n    c = n\\n    D = dict((index, Node(obs.reshape(-1, p), alpha)) for index, obs in enumerate(data))\\n    T = list(range(n))\\n    T_record = list(T)\\n    rk_record = [1]\\n    \\n    while c > 1:\\n        max_rk = -INFINITY\\n        node_merge = None\\n        left_merge = -1\\n        right_merge = -1\\n        \\n        for i, j in it.combinations(D.keys(), 2):\\n            Di = D[i]\\n            Dj = D[j]\\n            Dk = Node.merge_node(Di, Dj)\\n            \\n            likelihood_i = likelihood(Di.data)\\n            likelihood_j = likelihood(Dj.data)\\n            likelihood_k = likelihood(Dk.data)\\n            \\n            pi_k = Dk.pi_k\\n\\n            rk = (pi_k * likelihood_k) / (pi_k * likelihood_k + (1 - pi_k) * likelihood_i * likelihood_j)\\n\\n            if rk > max_rk:\\n                max_rk = rk\\n                node_merge = Dk\\n                left_merge = i\\n                right_merge = j\\n        \\n        #delete merged nodes and store new node\\n        del D[right_merge]\\n        D[left_merge] = node_merge\\n\\n        #store the current tree structure and value of rk\\n        for item_index, node_index in enumerate(T):\\n            if node_index == right_merge:\\n                T[item_index] = left_merge\\n        T_record.append(list(T))\\n        rk_record.append(max_rk)\\n        \\n        c -= 1\\n        \\n    return T_record, rk_record\\n        \\n\\nclass Node(object):\\n    \"\"\"\\n    Node class used in Bayesian hierarchical clustering algorithm. Main purpose is to store values of dk and pi_k for each node.\\n    \\n    Attributes\\n    ----------\\n    data : 2D numpy array\\n        Data with rows as observations and columns as variables.\\n    dk : float\\n        Some kind of number for computing probabilities\\n    pi_k : float\\n        For to compute merge probability\\n        \\n    Methods\\n    -------\\n    __init__(self, data, likelihood, alpha = 1)\\n        Instantiation operation.\\n    merge_node(cls, node1, node2, alpha = 1)\\n        Method that merges two Nodes into one new Node and return the new Node.\\n    \"\"\"\\n    \\n    def __init__(self, data, alpha = 1, dk = 1, pi_k = 1):\\n        \"\"\"\\n        Instantiation operation.\\n        \\n        Parameters\\n        ----------\\n        data : 2D numpy array\\n            Data with rows as observations and columns as variables.\\n        likelihood : function\\n            Function that returns the likelihood of data, sampling distribution in BHC model.\\n        alpha : float\\n            Concentration parameter in model.\\n        log_dk : float\\n            Cached probability variable. Do not define if the node is a leaf.\\n        log_pi : float\\n            Cached probability variable. Do not define if the node is a leaf.\\n        \"\"\"\\n        \\n        #initialized according to paper\\n        self.data = data\\n        self.dk = dk\\n        self.pi_k = pi_k\\n\\n    @classmethod\\n    def merge_node(cls, node1, node2, alpha = 1):\\n        \"\"\"\\n        Merge two Nodes into one new Node and return the new Node.\\n        \\n        Parameters\\n        ----------\\n        node1 : Node\\n            First Node.\\n        node2 : Node\\n            Second Node.\\n        \"\"\"\\n\\n        cdef np.ndarray[dtype = double, ndim = 2] data\\n        cdef double nk\\n        \\n        data = np.vstack((node1.data, node2.data))\\n\\n        nk = data.shape[0]\\n        dk = alpha * gamma(nk) + node1.dk * node2.dk\\n        pi_k = alpha * gamma(nk) / dk\\n\\n        return cls(data, alpha, dk, pi_k)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-125>\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\site-packages\\Cython\\Build\\IpythonMagic.py\u001b[0m in \u001b[0;36mcython\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         self._build_extension(extension, lib_dir, pgo_step_name='use' if args.pgo else None,\n\u001b[1;32m--> 333\u001b[1;33m                               quiet=args.quiet)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\site-packages\\Cython\\Build\\IpythonMagic.py\u001b[0m in \u001b[0;36m_build_extension\u001b[1;34m(self, extension, lib_dir, temp_dir, pgo_step_name, quiet)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[0mold_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mold_threshold\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    306\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                                      \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                                      force=self.force)\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mcustomize_compiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# If we are cross-compiling, init the compiler now (if we are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\distutils\\ccompiler.py\u001b[0m in \u001b[0;36mnew_compiler\u001b[1;34m(plat, compiler, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;31m# with classes that expect verbose to be the first positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;31m# argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\distutils\\cygwinccompiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mCygwinCCompiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;31m# ld_version >= \"2.13\" support -shared so use it instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\erics\\Anaconda3\\lib\\distutils\\cygwinccompiler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, verbose, dry_run, force)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# same as the rest of binutils ( also ld )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# dllwrap 2.10.90 is buggy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld_version\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;34m\"2.10.90\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinker_dll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gcc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from scipy.special import gamma\n",
    "from scipy.special import multigammaln\n",
    "from numpy.math cimport INFINITY\n",
    "from scipy.stats import multivariate_normal\n",
    "cimport numpy as np\n",
    "\n",
    "\n",
    "def BHC_cython(data, likelihood, alpha):\n",
    "    \"\"\"`\n",
    "    Bayesian hierarchical clustering algorithm, direct implementation from paper.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 2D numpy array\n",
    "        Data with rows as observations and columns as variables.\n",
    "    likelihood : function\n",
    "        Function that returns the marginal likelihood of data in BHC model.\n",
    "    alpha : float\n",
    "        Concentration parameter in model.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_record : list(list(int))\n",
    "        Cluster structure in each iteration.\n",
    "    rk_record : list(float)\n",
    "        Merge probability (rk) in each iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    cdef int n, c, i, j\n",
    "    cdef float max_rk\n",
    "    cdef int merge_index1, merge_index2\n",
    "    cdef double pi_k, rk\n",
    "    cdef int node_index, item_index\n",
    "    cdef double likelihood_i, likelihood_j, likelihood_k\n",
    "    cdef T_record, rk_record\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "    c = n\n",
    "    D = dict((index, Node(obs.reshape(-1, p), alpha)) for index, obs in enumerate(data))\n",
    "    T = list(range(n))\n",
    "    T_record = list(T)\n",
    "    rk_record = [1]\n",
    "    \n",
    "    while c > 1:\n",
    "        max_rk = -INFINITY\n",
    "        node_merge = None\n",
    "        left_merge = -1\n",
    "        right_merge = -1\n",
    "        \n",
    "        for i, j in it.combinations(D.keys(), 2):\n",
    "            Di = D[i]\n",
    "            Dj = D[j]\n",
    "            Dk = Node.merge_node(Di, Dj)\n",
    "            \n",
    "            likelihood_i = likelihood(Di.data)\n",
    "            likelihood_j = likelihood(Dj.data)\n",
    "            likelihood_k = likelihood(Dk.data)\n",
    "            \n",
    "            pi_k = Dk.pi_k\n",
    "\n",
    "            rk = (pi_k * likelihood_k) / (pi_k * likelihood_k + (1 - pi_k) * likelihood_i * likelihood_j)\n",
    "\n",
    "            if rk > max_rk:\n",
    "                max_rk = rk\n",
    "                node_merge = Dk\n",
    "                left_merge = i\n",
    "                right_merge = j\n",
    "        \n",
    "        #delete merged nodes and store new node\n",
    "        del D[right_merge]\n",
    "        D[left_merge] = node_merge\n",
    "\n",
    "        #store the current tree structure and value of rk\n",
    "        for item_index, node_index in enumerate(T):\n",
    "            if node_index == right_merge:\n",
    "                T[item_index] = left_merge\n",
    "        T_record.append(list(T))\n",
    "        rk_record.append(max_rk)\n",
    "        \n",
    "        c -= 1\n",
    "        \n",
    "    return T_record, rk_record\n",
    "        \n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Node class used in Bayesian hierarchical clustering algorithm. Main purpose is to store values of dk and pi_k for each node.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    data : 2D numpy array\n",
    "        Data with rows as observations and columns as variables.\n",
    "    dk : float\n",
    "        Some kind of number for computing probabilities\n",
    "    pi_k : float\n",
    "        For to compute merge probability\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    __init__(self, data, likelihood, alpha = 1)\n",
    "        Instantiation operation.\n",
    "    merge_node(cls, node1, node2, alpha = 1)\n",
    "        Method that merges two Nodes into one new Node and return the new Node.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, alpha = 1, dk = 1, pi_k = 1):\n",
    "        \"\"\"\n",
    "        Instantiation operation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : 2D numpy array\n",
    "            Data with rows as observations and columns as variables.\n",
    "        likelihood : function\n",
    "            Function that returns the likelihood of data, sampling distribution in BHC model.\n",
    "        alpha : float\n",
    "            Concentration parameter in model.\n",
    "        log_dk : float\n",
    "            Cached probability variable. Do not define if the node is a leaf.\n",
    "        log_pi : float\n",
    "            Cached probability variable. Do not define if the node is a leaf.\n",
    "        \"\"\"\n",
    "        \n",
    "        #initialized according to paper\n",
    "        self.data = data\n",
    "        self.dk = dk\n",
    "        self.pi_k = pi_k\n",
    "\n",
    "    @classmethod\n",
    "    def merge_node(cls, node1, node2, alpha = 1):\n",
    "        \"\"\"\n",
    "        Merge two Nodes into one new Node and return the new Node.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node1 : Node\n",
    "            First Node.\n",
    "        node2 : Node\n",
    "            Second Node.\n",
    "        \"\"\"\n",
    "\n",
    "        cdef np.ndarray[dtype = double, ndim = 2] data\n",
    "        cdef double nk\n",
    "        \n",
    "        data = np.vstack((node1.data, node2.data))\n",
    "\n",
    "        nk = data.shape[0]\n",
    "        dk = alpha * gamma(nk) + node1.dk * node2.dk\n",
    "        pi_k = alpha * gamma(nk) / dk\n",
    "\n",
    "        return cls(data, alpha, dk, pi_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications to simulated data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "y1 = np.random.multivariate_normal([0, 0], np.eye(2) * 0.1, n)\n",
    "y2 = np.random.multivariate_normal([1, 0], np.eye(2) * 0.3, n)\n",
    "y3 = np.random.multivariate_normal([0, 1], np.eye(2) * 0.5, n)\n",
    "y4 = np.random.multivariate_normal([-1, 1], np.eye(2) * 0.7, n)\n",
    "y5 = np.random.multivariate_normal([0, -1], np.eye(2) * 0.9, n)\n",
    "simu_true_cluster = np.repeat(list(range(1, 6)), 10)\n",
    "\n",
    "simulate_data = np.vstack((y1, y2, y3, y4, y5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def purity_score(cluster_true, cluster_pred):\n",
    "    \"\"\"\n",
    "    Function that returns the purity scores of each cluster given the predicted clusters and the true clusters\n",
    "    \"\"\"\n",
    "    \n",
    "    def most_common(lst):\n",
    "        \"\"\"Helper function that finds the most frequent item in a list\"\"\"\n",
    "        return max(set(lst), key = lst.count)\n",
    "    \n",
    "    purity = []\n",
    "    for cluster in set(cluster_pred):\n",
    "        np.where(np.array(cluster_pred) == cluster)\n",
    "        cluster_element = [cluster_true[index] for index in np.where(np.array(cluster_pred) == cluster)[0]]\n",
    "        dominant_item = most_common(cluster_element)\n",
    "        purity.append(cluster_element.count(dominant_item) / len(cluster_element))\n",
    "        \n",
    "    return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications to real datasets\n",
    "We tested our BHC algorithm on the glass dataset mentioned in the original paper, as well as the famous iris dataset by Fisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glass = pd.read_csv(\"data/glass.data\", index_col=0, header=None)\n",
    "iris = pd.read_csv(\"data/iris.data\", header=None)\n",
    "glass_x = glass.iloc[:, 0:9]\n",
    "iris_x = iris.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative analysis with competing algorithms\n",
    "In this section, we will apply the traditional hierarchical clustering with single linkage and K-means clustering to our simulated and real world datasets and compare their performance with the Bayesian hierarchical clustering algorithm we implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_df = pd.DataFrame(columns = (\"Hierarchical clustering\", \"K-means\", \"BHC\"))\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree\n",
    "HC = linkage(simulate_data, 'single')\n",
    "HC_cluster = cut_tree(HC, 5)\n",
    "purity_HC_simu = np.mean(purity_score(simu_true_cluster, HC_cluster.flatten()))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 5, random_state=0).fit(simulate_data)\n",
    "kmeans_cluster = kmeans.labels_\n",
    "purity_KM_simu = np.mean(purity_score(simu_true_cluster, kmeans_cluster))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heller, K. A., & Ghahramani, Z. (2005). Bayesian Hierarchical Clustering. Neuroscience, 6(section 2), 297â€“304. doi:10.1145/1102351.1102389\n",
    "\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
